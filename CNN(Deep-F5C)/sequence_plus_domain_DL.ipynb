{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import KFold "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define methods: \n",
    "def train_test_split(data,label,train_size = 0.8):\n",
    "    if data.shape[0] != label.shape[0]:\n",
    "        return\n",
    "    else:\n",
    "        num_samples = data.shape[0]\n",
    "        train_sample = int(num_samples * train_size)\n",
    "\n",
    "        train_data = data[:train_sample]\n",
    "        train_labels = label[:train_sample]\n",
    "\n",
    "        test_data = data[train_sample:]\n",
    "        test_labels = label[train_sample:]\n",
    "\n",
    "        return(train_data,train_labels,test_data,test_labels)\n",
    "    \n",
    "class Net_conv(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net_conv, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(1, 16, kernel_size=3, stride=1, padding=1)\n",
    "        self.dropout1 = nn.Dropout(0.2)  ",
    "        self.conv2 = nn.Conv1d(16, 32, kernel_size=3, stride=1, padding=1)\n",
    "        self.dropout2 = nn.Dropout(0.2)  ",
    "        self.fc1 = nn.Linear(7840, 64)\n",
    "        self.dropout3 = nn.Dropout(0.5)  ",
    "        self.fc2 = nn.Linear(64, 32)\n",
    "        self.fc3 = nn.Linear(32, 1)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.conv1(x))\n",
    "        x = self.dropout1(x)  ",
    "        x = self.relu(self.conv2(x))\n",
    "        x = self.dropout2(x)  ",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.relu(self.fc1(x)) \n",
    "        x = self.dropout3(x)  ",
    "        x = self.relu(self.fc2(x))\n",
    "        x = self.sigmoid(self.fc3(x))\n",
    "        return x\n",
    "    \n",
    "def metrics_output(preds,labels):\n",
    "    metrics_fpr, metrics_tpr, thresholds = roc_curve(labels.squeeze(-1), preds.squeeze(-1))\n",
    "    roc_auc = auc(metrics_fpr, metrics_tpr)\n",
    "\n",
    "    best_threshold = thresholds[np.argmax(metrics_tpr - metrics_fpr)]\n",
    "\n",
    "    test_pred_binary = np.where(preds > best_threshold, 1 , 0)\n",
    "\n",
    "    metrics_tn, metrics_fp, metrics_fn, metrics_tp = confusion_matrix(np.squeeze(labels,axis=-1), np.squeeze(test_pred_binary,axis=-1)).ravel()\n",
    "    metrics_sn = metrics_tp / (metrics_tp + metrics_fn)\n",
    "    metrics_sp = metrics_tn / (metrics_tn + metrics_fp)\n",
    "    metrics_ACC = (metrics_tp + metrics_tn) / (metrics_tn + metrics_fp + metrics_fn + metrics_tp)\n",
    "    metrics_pre = metrics_tp / (metrics_tp + metrics_fp)\n",
    "    metrics_F1 = 2 * (metrics_pre * metrics_sn) / (metrics_pre + metrics_sn)\n",
    "    metrics_MCC = (metrics_tp * metrics_tn - metrics_fp * metrics_fn) / math.sqrt((metrics_tp + metrics_fp)*\n",
    "                                                                                  (metrics_tp + metrics_fn)*\n",
    "                                                                                  (metrics_tn + metrics_fp)*\n",
    "                                                                                  (metrics_tn + metrics_fn))\n",
    "    \n",
    "    return (metrics_fpr, metrics_tpr, roc_auc, metrics_sn, metrics_sp, metrics_ACC, metrics_F1, metrics_MCC)\n",
    "\n",
    "def plot_loss_curve(losses1, losses2=None):\n",
    "    epochs = range(1, len(losses1) + 1)\n",
    "    plt.plot(epochs, losses1, 'b', label='Train losses')\n",
    "\n",
    "    if losses2 is not None:\n",
    "        plt.plot(epochs, losses2, 'r', label='Validation losses')\n",
    "\n",
    "    plt.title('Training Loss')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\n",
    "    'AUC_val': [np.nan]*20,\n",
    "    'ACC_val': [np.nan]*20,\n",
    "    'MCC_val': [np.nan]*20,\n",
    "    'Sn_val': [np.nan]*20,\n",
    "    'Sp_val': [np.nan]*20,\n",
    "    'AUC_test': [np.nan]*20,\n",
    "    'ACC_test': [np.nan]*20,\n",
    "    'MCC_test': [np.nan]*20,\n",
    "    'Sn_test': [np.nan]*20,\n",
    "    'Sp_test': [np.nan]*20\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_domain = pd.read_csv('./pos_domain_encoding.csv') \n",
    "neg_domain = pd.read_csv('./neg_domain_encoding.csv') \n",
    "\n",
    "pos_sequence = pd.read_csv('./pos_encoding_OH_ND.csv') \n",
    "neg_sequence = pd.read_csv('./neg_encoding_OH_ND.csv') \n",
    "\n",
    "pos = pd.merge(pos_domain, pos_sequence)\n",
    "neg = pd.merge(neg_domain, neg_sequence)\n",
    "\n",
    "pos = pos.iloc[:,1:]\n",
    "neg = neg.iloc[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"mps\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_test_accuracy = 0.0\n",
    "\n",
    "\n",
    "for i in range(0, 13):\n",
    "    print(f\"Processing on neg Part: {i+1}...\")\n",
    "    \n",
    "    seed_value = i\n",
    "    neg = neg.sample(n=1892, random_state=seed_value)\n",
    "\n",
    "    raw_datas = np.concatenate((pos,neg),axis = 0)\n",
    "    raw_datas = np.expand_dims(raw_datas, axis = -2)\n",
    "    \n",
    "    raw_labels = np.concatenate(([1] * pos.shape[0], [0] * neg.shape[0]),axis = 0)\n",
    "    raw_labels = np.expand_dims(raw_labels,-1)\n",
    "    \n",
    "    np.random.seed(i)\n",
    "    indices = np.random.permutation(raw_labels.shape[0])\n",
    "    \n",
    "    datas = raw_datas[indices,:,:]\n",
    "    labels = raw_labels[indices,:]\n",
    "    \n",
    "    (two_datas,two_labels,test_datas,test_labels) = train_test_split(datas, labels)\n",
    "    test_datas = torch.from_numpy(test_datas.astype(np.float32)).to(device).type(torch.float)\n",
    "    test_labels = torch.from_numpy(test_labels.astype(np.float32)).to(device).type(torch.float)\n",
    "    \n",
    "    num_folds = 5\n",
    "    kf = KFold(n_splits=num_folds, shuffle=True, random_state=i)\n",
    "    \n",
    "    val_accuracy_per_fold = []\n",
    "    models = []\n",
    "    \n",
    "    best_val_accuracy = 0.0\n",
    "    \n",
    "    for fold, (train_indices, val_indices) in enumerate(kf.split(two_datas)):\n",
    "        print(f\"Training on fold {fold + 1}...\")\n",
    "        \n",
    "        train_datas, train_labels = two_datas[train_indices], two_labels[train_indices]\n",
    "        val_datas, val_labels = two_datas[val_indices], two_labels[val_indices]\n",
    "        \n",
    "        train_datas = torch.from_numpy(train_datas.astype(np.float32)).to(device).type(torch.float)\n",
    "        train_labels = torch.from_numpy(train_labels.astype(np.float32)).to(device).type(torch.float)\n",
    "        val_datas = torch.from_numpy(val_datas.astype(np.float32)).to(device).type(torch.float)\n",
    "        val_labels = torch.from_numpy(val_labels.astype(np.float32)).to(device).type(torch.float)\n",
    "        \n",
    "        net = Net_conv().to(device)\n",
    "        criterion = nn.BCELoss()\n",
    "        optimizer = optim.Adam(net.parameters(), lr=0.001)\n",
    "        scheduler = lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.93)\n",
    "        \n",
    "        num_epochs = 50\n",
    "    \n",
    "        train_losses = []\n",
    "        validation_losses = []\n",
    "        \n",
    "        for epoch in range(num_epochs):\n",
    "            optimizer.zero_grad()\n",
    "            outputs = net(train_datas)\n",
    "            loss = criterion(outputs, train_labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "            \n",
    "            train_losses.append(loss.item())\n",
    "            if (epoch + 1) % 10 == 0:\n",
    "                print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {loss.item()}\")\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                net.eval()\n",
    "                \n",
    "                preds = net(val_datas)\n",
    "                #preds = preds.detach().cpu().numpy()####\n",
    "                \n",
    "                #val_labels = val_labels.to(\"cpu\").numpy()\n",
    "                #print(val_labels.dtype)\n",
    "                \n",
    "                validation_loss = criterion(preds, val_labels)\n",
    "                \n",
    "                validation_losses.append(validation_loss.item())\n",
    "                \n",
    "        print(f\"plot of training and validation loss in fold: {fold+1}\")        \n",
    "        plot_loss_curve(train_losses, validation_losses)\n",
    "                \n",
    "        with torch.no_grad():\n",
    "            net.eval()\n",
    "            \n",
    "            preds = net(val_datas)\n",
    "            preds = preds.detach().cpu().numpy() \n",
    "            \n",
    "            val_labels = val_labels.to(\"cpu\").numpy()\n",
    "            \n",
    "            metrics_fpr, metrics_tpr, roc_auc, metrics_sn, metrics_sp, metrics_ACC, metrics_F1, metrics_MCC = metrics_output(preds,val_labels)\n",
    "            \n",
    "            val_accuracy = metrics_ACC\n",
    "            val_accuracy_per_fold.append(val_accuracy)\n",
    "            \n",
    "            models.append(net.state_dict().copy())\n",
    "            \n",
    "                \n",
    "        if(val_accuracy > best_val_accuracy):\n",
    "            best_val_accuracy = val_accuracy\n",
    "            best_model_state_dict = net.state_dict().copy()\n",
    "            \n",
    "            roc_auc = roc_auc\n",
    "            metrics_ACC = metrics_ACC\n",
    "            metrics_MCC = metrics_MCC\n",
    "            metrics_sn = metrics_sn\n",
    "            metrics_sp = metrics_sp\n",
    "                \n",
    "        df.iloc[i,0] = roc_auc\n",
    "        df.iloc[i,1] = metrics_ACC\n",
    "        df.iloc[i,2] = metrics_MCC\n",
    "        df.iloc[i,3] = metrics_sn\n",
    "        df.iloc[i,4] = metrics_sp\n",
    "                \n",
    "    print(f\"val_accuracy_per_fold: {val_accuracy_per_fold}\")\n",
    "    print(f\"best_val_accuracy: {best_val_accuracy}\")\n",
    "                \n",
    "    net = Net_conv().to(device)\n",
    "    net.load_state_dict(best_model_state_dict)\n",
    "        \n",
    "    with torch.no_grad():\n",
    "        net.eval()\n",
    "        \n",
    "        preds = net(test_datas)\n",
    "        preds = preds.detach().cpu().numpy() \n",
    "        \n",
    "        test_labels = test_labels.to(\"cpu\").numpy()\n",
    "        \n",
    "        metrics_fpr, metrics_tpr, roc_auc, metrics_sn, metrics_sp, metrics_ACC, metrics_F1, metrics_MCC = metrics_output(preds,test_labels)\n",
    "        \n",
    "        df.iloc[i,5] = roc_auc\n",
    "        df.iloc[i,6] = metrics_ACC\n",
    "        df.iloc[i,7] = metrics_MCC\n",
    "        df.iloc[i,8] = metrics_sn\n",
    "        df.iloc[i,9] = metrics_sp\n",
    "            \n",
    "        test_accuracy = metrics_ACC\n",
    "\n",
    "        print(\"Test accuracy: \", test_accuracy)\n",
    "        print(df)\n",
    "\n",
    "        if(test_accuracy > best_test_accuracy):\n",
    "            best_test_accuracy = test_accuracy\n",
    "            best_model_state_dict = net.state_dict().copy()\n",
    "            \n",
    "            torch.save(best_model_state_dict, '/Users/jiaming/Desktop/f5c/webserver/model_parameters.pth')\n",
    "            \n",
    "            print(f\"state of current best model renewed with current best test accuracy: {best_test_accuracy}\")\n",
    "            \n",
    "        print(f\"state of current best model maintained with current best test accuracy: {best_test_accuracy}\")\n",
    "        \n",
    "print(f\"best_test_accuracy_for_all_10_loops: {best_test_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_means = df.mean()\n",
    "column_means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
